{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 2 по ML\n",
        "Нужно написать python класс градиентного бустинга и побить другую модель на предоставленном baseline\n",
        "\n",
        "## Критерии оценки\n",
        "- Ваш ноутбук будет запущен через ```run all``` - он не должен упасть (допускается падение из-за отсутствия библиотеки, которую можно поставить через pip install)\n",
        "- Вот этот код (внизу ноутбука) ```assert imp_my_little_model > imp_baseline_model``` не вызвал ошибок (успешно отработал)\n",
        "\n",
        "- реализованы следующие гиперпараметры\n",
        "  - вы реализовали гиперпараметр ```learning_rate```\n",
        "  - вы реализовали гиперпараметр ```n_estimators```\n",
        "  - вы реализовали гиперпараметр ```max_depth```\n",
        "  - вы реализовали гиперпараметр ```bagging_fraction```\n",
        "\n",
        "- Вы реализовали [Huber loss function](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C_%D0%A5%D1%8C%D1%8E%D0%B1%D0%B5%D1%80%D0%B0) - она записана как отдельная def функция вне класса - и используется в вашем классе для расчета\n",
        "\n",
        "----\n",
        "*Для успешной сдачи дз нужно выполнить полностью каждый пункт выше*\n",
        "\n",
        "- оценка 5 будет поставлена, если каждый пункт выполнен без недочетов\n",
        "- оценка 4 будет поставлена, если будет найден один недочет\n",
        "- незачет будет пославлен, если недочетов будет два или более\n",
        "- незачет будет пославлен, если какой либо пункт не выполнен\n"
      ],
      "metadata": {
        "id": "Xj_j1Ibc6376"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1YyKnF4T6e5Y",
        "outputId": "6d03e042-64f1-4c0f-bf5b-a9dde048b565"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "\n",
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "Fuou3iRh67G-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fac16d-69f1-41ec-8629-56242a6bbee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "TSWaYEYyT0iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, target = shap.datasets.california()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "M4B4Ep5U68x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Не меняйте название для предскзаний preds_my_little_model, иначе не получится сдать это ДЗ (сломается код)\n",
        "\n",
        "Некоторые правила\n",
        "- Нельзя использовать никакие другие алгоритмы моделей внутри вашего класса, кроме DecisionTreeRegressor.\n",
        "- Код вашего бустинга должен быть написан в классе, у класса должно быть два ожидаемых метода : ```fit``` и ```predict```.\n",
        "- Нельзя менять датасет (и модифицировать тоже, например заполнять nan или применять scaler) или baseline модель\n",
        "- Нельзя поднимать число n_estimators вашей модели выше 100 (чтобы результат был сравним с моделью-конкурентом ```GradientBoostingRegressor```)"
      ],
      "metadata": {
        "id": "A6-T1zHhWl69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *это место для вашего кода* ↓↓↓\n"
      ],
      "metadata": {
        "id": "61wEAl-UIA4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    diff = np.abs(y_true - y_pred) # Вычисляем абсолютную разницу между истинными значениями и предсказанными\n",
        "\n",
        "    quadratic_part = np.where(diff <= delta, 0.5 * diff ** 2, delta * (diff - 0.5 * delta)) # Штрафуем ошибки линейно, если абсолютная разница меньше или равна delta\n",
        "\n",
        "    return np.mean(quadratic_part) # Возвращаем среднее значение потерь"
      ],
      "metadata": {
        "id": "5ahK530JP-TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGradBoosting:\n",
        "    def __init__(\n",
        "      self,\n",
        "      learning_rate=0.01,\n",
        "      n_estimators=100,\n",
        "      max_depth=15,\n",
        "      random_state=0,\n",
        "      bagging_fraction=0.75\n",
        "  ):\n",
        "      self.learning_rate = learning_rate\n",
        "      self.n_estimators = n_estimators\n",
        "      self.max_depth = max_depth\n",
        "      self.random_state = random_state\n",
        "      self.bagging_fraction = bagging_fraction\n",
        "      self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = [] # Очищаем список деревьев\n",
        "        residuals = y.copy() # Копируем целевую переменную, чтобы не изменять оригинал\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "            sample_indices = np.random.choice(len(X), size=int(self.bagging_fraction * len(X)), replace=False)\n",
        "            X_sampled = X_train.iloc[sample_indices]  # Используем iloc для извлечения строк по индексам\n",
        "            residuals_sampled = residuals[sample_indices]\n",
        "            tree.fit(X_sampled, residuals_sampled)\n",
        "\n",
        "            self.trees.append(tree)\n",
        "            predictions = tree.predict(X)\n",
        "            residuals -= self.learning_rate * huber_loss(y, predictions)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.zeros(len(X))\n",
        "\n",
        "        for tree in self.trees:\n",
        "            predictions += self.learning_rate * tree.predict(X)\n",
        "\n",
        "        return predictions # Возвращаем вектор предсказанных значений"
      ],
      "metadata": {
        "id": "PPwM5ru6ITFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_little_model = MyGradBoosting()\n",
        "my_little_model.fit(X_train, y_train)\n",
        "\n",
        "preds_my_little_model = my_little_model.predict(X_test)"
      ],
      "metadata": {
        "id": "jDMV0_KfBDEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# самопроверки\n",
        "assert preds_my_little_model.shape == y_test.shape, 'что-то не так с выходным размером предикта'"
      ],
      "metadata": {
        "id": "CPzhitJHKdXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *это место для вашего кода* ↑↑↑"
      ],
      "metadata": {
        "id": "XekwIQWHIKtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *ниже ничего менять не нужно*\n",
        "## Это класс судья - он решит, какая модель оказалась лучше, ваша, или GradientBoostingRegressor из sklearn\n",
        "Если ячейка ниже завершилась ошибкой, нужно поменять код вашей модели и попробовать еще раз, до тех пор, пока не получите сообщение \"Ура, получилось!\""
      ],
      "metadata": {
        "id": "WrLezIsFHUP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = GradientBoostingRegressor(random_state=4, verbose=0)\n",
        "baseline_model = baseline_model.fit(X_train, y_train)\n",
        "preds_baseline_model = baseline_model.predict(X_test)\n",
        "print('mape - ваша модель', mean_absolute_percentage_error(y_test, preds_my_little_model))\n",
        "print('mape - baseline', mean_absolute_percentage_error(y_test, preds_baseline_model))\n",
        "\n",
        "final_estimator = RandomForestRegressor(random_state=16)\n",
        "final_estimator = final_estimator.fit(\n",
        "    np.hstack((preds_baseline_model.reshape(-1, 1), preds_my_little_model.reshape(-1, 1))),\n",
        "    y_test\n",
        ")\n",
        "\n",
        "imp_baseline_model, imp_my_little_model = final_estimator.feature_importances_\n",
        "result_message = f\"baseline важность: {imp_baseline_model:0.3f}; важность вашей модели: {imp_my_little_model:0.3f}\"\n",
        "\n",
        "assert imp_my_little_model > imp_baseline_model,  f'попробуй еще раз: {result_message}'\n",
        "print('Ура, получилось!',  result_message)"
      ],
      "metadata": {
        "id": "5cwE3WwPBcKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca68120-015c-4d9d-b8d1-fe45bc5d7d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mape - ваша модель 0.18370268368520962\n",
            "mape - baseline 0.2152446498010688\n",
            "Ура, получилось! baseline важность: 0.159; важность вашей модели: 0.841\n"
          ]
        }
      ]
    }
  ]
}